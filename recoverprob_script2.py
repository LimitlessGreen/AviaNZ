# -*- coding: utf-8 -*-
"""
Script to recover file probabilities, like the ones generated by filelabel2
in the script BatSearch.py

This script:
    1) Recover the appropriate model
    2) Predict the labels for the testing dataset
    3) Evaluate the file probabilities with filelabel2
    4) Save files, divided in  true class with the probabilities
"""

import json
import numpy as np
import wavio
import SignalProc
import math
import Segment
import pyqtgraph as pg
import pyqtgraph.exporters as pge
import os

#tensorflow libraries
import tensorflow
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.models import load_model

import librosa
import WaveletSegment
import WaveletFunctions

def ClickSearch(dirName, file, fs, featuress, count, Train=False):
    """
    ClickSearch search for clicks into file in directory dirName, saves 
    dataset, and return click_label and dataset
    
    The search is made on the spectrogram image generated with parameters
    (1024,512)
    Click presence is assested for each spectrogram column: if the mean in the
    frequency band [3000, 5000] (*) is bigger than a treshold we have a click
    thr=mean(all_spec)+std(all_spec) (*)
    
    The clicks are discarded if longer than 0.5 sec
    
    Clicks are stored into featuress using updateDataset
    
    """
    
    print("Click search on ",file)
    filename = dirName + '\\' + file
    
    #Read audiodata
    audiodata = wavio.read(filename)
    sp = SignalProc.SignalProc(1024, 512) #outside?
    sp.data = audiodata.data
    duration=audiodata.nframes/fs
    
    #copyed from sp.wavRead to make everything consistent
    # take only left channel
    if np.shape(np.shape(sp.data))[0] > 1:
        sp.data = sp.data[:, 0]
    sp.audioFormat.setChannelCount(1)
     # force float type
    if sp.data.dtype != 'float':
        sp.data = sp.data.astype('float')
    sp.audioFormat.setSampleSize(audiodata.sampwidth * 8)
    
    #Spectrogram
    sp.samplerate= fs
    sgraw= sp.spectrogram(1024, 512, 'Blackman')
    imspec=(10.*np.log10(sgraw)).T #transpose
    imspec=np.flipud(imspec) #updown 

    df=16000/(np.shape(imspec)[0]+1) #frequency increment 
    dt=duration/(np.shape(imspec)[1]+1) #timeincrement
    up_len=math.ceil(0.5/dt) #0.5 second lenth in indices  
    
    #Frequency band
    f0=3000
    index_f0=-1+math.floor(f0/df) #lower bound needs to be rounded down
#    print(f0,index_f0)
    f1=5000
    index_f1=-1+math.ceil(f1/df) #upper bound needs to be rounded up
    
    #Mean in the frequency band
    mean_spec=np.mean(imspec[index_f0:index_f1,:], axis=0) #added 0.01 to avoid divition by 0

    #Threshold
    mean_spec_all=np.mean(imspec, axis=0)[2:]
    thr_spec=(np.mean(mean_spec_all)+np.std(mean_spec_all))*np.ones((np.shape(mean_spec)))
    
    ##clickfinder
    #check when the mean is bigger than the threshold
    #clicks is an array which elements are equal to 1 only where the sum is bigger 
    #than the mean, otherwise are equal to 0
    clicks=np.where(mean_spec>thr_spec,1,0)
    clicks_indices=np.nonzero(clicks)
    print(np.shape(clicks_indices))
    #check: if I have found somenthing
    if np.shape(clicks_indices)[1]==0:
        #If not: label = None 
        click_label='None'
        #check if I need to return something different
        return click_label, featuress, count
        #not saving spectrograms
    
#    DIscarding segments too long or too shorts and saving spectrogram images
    
    #Read annotation file: if in Train mode
    if Train==True:
        annotation_file=filename +'.data'
        if os.path.isfile(annotation_file):
            segments = Segment.SegmentList()
            segments.parseJSON(annotation_file)
            thisSpSegs = np.arange(len(segments)).tolist()
        else:
            segments=[]
            thisSpSegs=[]
    else:
        segments=[]
        thisSpSegs=[]
        
    click_start=clicks_indices[0][0]
    click_end=clicks_indices[0][0]  
    for i in range(1,np.shape(clicks_indices)[1]):
        if clicks_indices[0][i]==click_end+1:
            click_end=clicks_indices[0][i]
        else:
            if click_end-click_start+1>up_len:
                clicks[click_start:click_end+1]=0
            else:
                #savedataset
                featuress, count=updateDataset3(file, dirName, featuress, count, imspec,  segments, thisSpSegs, click_start, click_end, dt, Train)
                #update
                click_start=clicks_indices[0][i]
                click_end=clicks_indices[0][i] 
                              
    #checking last loop with end
    if click_end-click_start+1>up_len:
        clicks[click_start:click_end+1]=0
    else:
        featuress, count = updateDataset3(file, dirName, featuress, count, imspec, segments, thisSpSegs, click_start, click_end, dt, Train)
        
    #updating click_inidice
    clicks_indices=np.nonzero(clicks)
    
    #Assigning: click label
    if np.shape(clicks_indices)[1]==0:
        click_label='None'
    else:
        click_label='Click'
    
    return click_label, featuress, count

def updateDataset3(file_name, dirName, featuress, count, spectrogram, segments, thisSpSegs, click_start, click_end, dt, Train=False):
    """
    Update Dataset with current segment
    It take a piece of the spectrogram with fixed length centered in the
    click 
    
    TRAIN MODE => stores the lables as well
    A spectrogram is labeled is the click is inside a segment
    We have 3 labels:
        0 => LT
        1 => ST
        2 => Noise
    """
    #I assign a label t the spectrogram only for Train Dataset
    click_start_sec=click_start*dt
    click_end_sec=click_end*dt
    if Train==True:
        assigned_flag=False #control flag
        for segix in thisSpSegs:
            seg = segments[segix]
            if isinstance(seg[4][0], dict):
                if seg[0]<=click_start_sec and seg[1]>=click_end_sec:
                    if 'Bat (Long Tailed)' == seg[4][0]["species"]:
                        spec_label = 0
                        assigned_flag=True
                        break
                    elif 'Bat (Short Tailed)' == seg[4][0]["species"]:
                        spec_label = 1
                        assigned_flag=True
                        break
                    elif 'Noise' == seg[4][0]["species"]:
                        spec_label = 2    
                        assigned_flag=True
                        break
                    else:
                        continue
                    
            elif isinstance(seg[4][0], str):
                # old format
                if seg[0]<=click_start_sec and seg[1]>=click_end_sec:
                    if 'Bat (Long Tailed)' == seg[4][0]["species"]:
                        spec_label = 0
                        assigned_flag=True
                        break
                    elif 'Bat (Short Tailed)' == seg[4][0]["species"]:
                        spec_label = 1
                        assigned_flag=True
                        break
                    elif 'Noise' == seg[4][0]["species"]:
                        spec_label = 2   
                        assigned_flag=True
                        break
                    else:
                        continue
        if assigned_flag==False:
            spec_label=2
    
# slice spectrogram   

    win_pixel=1 
    ls = np.shape(spectrogram)[1]-1
    click_center=int((click_start+click_end)/2)

    start_pixel=click_center-win_pixel
    if start_pixel<0:
        win_pixel2=win_pixel+np.abs(start_pixel)
        start_pixel=0
    else:
        win_pixel2=win_pixel
    
    end_pixel=click_center+win_pixel2
    if end_pixel>ls:
        start_pixel-=end_pixel-ls+1
        end_pixel=ls-1
#    if end_pixel-start_pixel != 10:
#        print("*******************************************",end_pixel,start_pixel)
        #this code above fails for sg less than 4 pixels wide   
    sgRaw=spectrogram[:,start_pixel:end_pixel+1] #not I am saving the spectrogram in the right dimension
    sgRaw=np.repeat(sgRaw,2,axis=1)
    sgRaw=(np.flipud(sgRaw)).T #flipped spectrogram to make it consistent with Niro Mewthod
    if Train==True:
        featuress.append([sgRaw.tolist(), file_name, count, spec_label])
    else:
        featuress.append([sgRaw.tolist(), file_name, count]) #not storing segment and label informations

    count += 1

    return featuress, count

def updateDataset4(file_name, dirName, featuress, count, spectrogram, segments, thisSpSegs, click_start, click_end, dt, Train=False):
    """
    Update Dataset with current segment
    It take a piece of the spectrogram with fixed length centered in the
    click 
    
    TRAIN MODE => stores the lables as well
    A spectrogram is labeled is the click it overlap a segment
    We have 3 labels:
        0 => LT
        1 => ST
        2 => Noise
    """
    #I assign a label t the spectrogram only for Train Dataset
    click_start_sec=click_start*dt
    click_end_sec=click_end*dt
    if Train==True:
        assigned_flag=False #control flag
        for segix in thisSpSegs:
            seg = segments[segix]
            
            if isinstance(seg[4][0], dict):
                if (seg[0]<=click_start_sec and seg[1]>=click_end_sec) or (seg[0]<=click_start_sec and seg[1]>=click_start_sec) or  (seg[1]>=click_end_sec and seg[0]<=click_end_sec):
                    if 'Bat (Long Tailed)' == seg[4][0]["species"]:
                        spec_label = 0
                        assigned_flag=True
                        break
                    elif 'Bat (Short Tailed)' == seg[4][0]["species"]:
                        spec_label = 1
                        assigned_flag=True
                        break
                    elif 'Noise' == seg[4][0]["species"]:
                        spec_label = 2    
                        assigned_flag=True
                        break
                    else:
                        continue
                    
            elif isinstance(seg[4][0], str):
                # old format
                if  (seg[0]<=click_start_sec and seg[1]>=click_end_sec) or (seg[0]<=click_start_sec and seg[1]>=click_start_sec) or  (seg[1]>=click_end_sec and seg[0]<=click_end_sec):
                    if 'Bat (Long Tailed)' == seg[4][0]["species"]:
                        spec_label = 0
                        assigned_flag=True
                        break
                    elif 'Bat (Short Tailed)' == seg[4][0]["species"]:
                        spec_label = 1
                        assigned_flag=True
                        break
                    elif 'Noise' == seg[4][0]["species"]:
                        spec_label = 2   
                        assigned_flag=True
                        break
                    else:
                        continue
        if assigned_flag==False:
            spec_label=2
    
# slice spectrogram   
    win_pixel=1 
    ls = np.shape(spectrogram)[1]-1
    click_center=int((click_start+click_end)/2)

    start_pixel=click_center-win_pixel
    if start_pixel<0:
        win_pixel2=win_pixel+np.abs(start_pixel)
        start_pixel=0
    else:
        win_pixel2=win_pixel
    
    end_pixel=click_center+win_pixel2
    if end_pixel>ls:
        start_pixel-=end_pixel-ls+1
        end_pixel=ls-1
#    if end_pixel-start_pixel != 10:
#        print("*******************************************",end_pixel,start_pixel)
        #this code above fails for sg less than 4 pixels wide
#    print(start_pixel, end_pixel)    
    sgRaw=spectrogram[:,start_pixel:end_pixel+1] #not I am saving the spectrogram in the right dimension
    sgRaw=np.repeat(sgRaw,2,axis=1)
    sgRaw=(np.flipud(sgRaw)).T #flipped spectrogram to make it consistent with Niro Mewthod
    if Train==True:
        featuress.append([sgRaw.tolist(), file_name, count, spec_label])
    else:
 #if testing: do not save label
        featuress.append([sgRaw.tolist(), file_name, count]) #not storing segment and label informations

    count += 1

    return featuress, count

#2nd option: 3 labels, evaluate it filewise
def File_label2(predictions, spec_id, segments_filewise_test, filewise_output, file_number ):
    """
    FIle_label2 use the predictions made by the CNN to update the filewise annotations
    when we have 3 labels: 0 (LT), 1(ST), 2 (Noise)
    
    METHOD: evaluation of probability over files
        P(2)>50% => Noise
        P(0)>70 => LT
        P(1)>70 => ST
        else => Both
    
     TODO: how can I had possible?
    """
   
    
    if len(predictions)!=np.shape(spec_id)[0]:
        print('ERROR: Number of labels is not equal to number of spectrograms' )
    
    file_probabilities=np.zeros((file_number,3))
    # Assesting file label
    for i in range(file_number):
        file = segments_filewise_test[i][0]
        file_prob=np.zeros((1,3))
        spec_num=0   #counts number of spectrograms per file
        #flag: if no click detected no spectrograms
        click_detected_flag=False
        #        looking for all the spectrogram related to this file

        for k in range(np.shape(spec_id)[0]):
            if spec_id[k][0]==file:
                click_detected_flag=True
                spec_num+=1
                file_prob[0][:]+=predictions[k][:]
#                print('check file_prob',file_prob)
        if click_detected_flag==True:
            file_prob/=spec_num
            file_prob*=100
            if file_prob[0][2]>90:
            #if file_prob[0][0]<5 and file_prob[0][1]<5:
                label='Noise'
            elif file_prob[0][0]-file_prob[0][1]>10:
                label='LT'
            elif file_prob[0][1]-file_prob[0][0]>10:
                label='ST'
#            elif file_prob[0][0]>80:
#                label='LT'
#            elif file_prob[0][1]>80:
#                label='ST'
            else:
                label='Both'
            
        else:
#            if no clicks => automatically Noise
            label='Noise'
            
        print('check file_prob',file_prob)
        filewise_output[i][3] = label
#        file_probabilities.append(file_prob)
        file_probabilities[i][:]=file_prob[0][:]
        
    return filewise_output, file_probabilities

def label_probability(predictions, spec_id, target_label, segments_filewise_test, filewise_output, file_number ):
    """
    Label_probability
    It stores probability vector associate with file labelled
    
    It check click label in the annotations and for each click stores:
        filename
        click_label (from annotations)
        probabilities
    
     TODO: how can I had possible?
    """
   
    print('assing spectrograms probabilities') 
    if len(predictions)!=np.shape(spec_id)[0]:
        print('ERROR: Number of labels is not equal to number of spectrograms' )
    
#    file_probabilities=np.zeros((file_number,3))
    LT_probabilities=[]
    ST_probabilities=[]
    Noise_probabilities=[]
    Both_probabilities=[]
    # Assesting file label
    for i in range(file_number):
        file = segments_filewise_test[i][0]
#        file_prob=np.zeros((1,3))
        spec_num=0   #counts number of spectrograms per file
        #flag: if no click detected no spectrograms
        click_detected_flag=False
        #        looking for all the spectrogram related to this file

        for k in range(np.shape(spec_id)[0]):
            if spec_id[k][0]==file:
               click_detected_flag=True
#                spec_num+=1
#                file_prob[0][:]+=predictions[k][:]
#                print('check file_prob',file_prob)
               if segments_filewise_test[i][1] == 'LT':
                   LT_probabilities.append([spec_id[k][0], target_label[k], predictions[k][:].tolist()])
               elif segments_filewise_test[i][1] == 'ST':
                   ST_probabilities.append([spec_id[k][0], target_label[k],  predictions[k][:].tolist()])
               elif segments_filewise_test[i][1] == 'Noise':
                   Noise_probabilities.append([spec_id[k][0], target_label[k],  predictions[k][:].tolist()])
               elif segments_filewise_test[i][1] == 'Both':
                   Both_probabilities.append([spec_id[k][0], target_label[k],  predictions[k][:].tolist()])
        if click_detected_flag==False:
            Noise_probabilities.append([file, 2, np.zeros((3,)).tolist()])
                
    return LT_probabilities, ST_probabilities, Noise_probabilities, Both_probabilities
                    
def label_probability2(predictions, spec_id, target_label, segments_filewise_test, filewise_output, file_number ):
    """
    Label_probability
    It stores the probabilities vector for each spectrogram
    
    For each file class it store:
        filename
        probability vector
    
     TODO: how can I had possible?
    """
   
    print('assing spectrograms probabilities') 
    if len(predictions)!=np.shape(spec_id)[0]:
        print('ERROR: Number of labels is not equal to number of spectrograms' )
    
#    file_probabilities=np.zeros((file_number,3))
    LT_probabilities=[]
    ST_probabilities=[]
    Noise_probabilities=[]
    Both_probabilities=[]
    # Assesting file label
    for i in range(file_number):
        file = segments_filewise_test[i][0]
#        file_prob=np.zeros((1,3))
        spec_num=0   #counts number of spectrograms per file
        #flag: if no click detected no spectrograms
        click_detected_flag=False
        #        looking for all the spectrogram related to this file

        for k in range(np.shape(spec_id)[0]):
            if spec_id[k][0]==file:
               click_detected_flag=True
#                spec_num+=1
#                file_prob[0][:]+=predictions[k][:]
#                print('check file_prob',file_prob)
               if segments_filewise_test[i][1] == 'LT':
                   LT_probabilities.append([spec_id[k][0], predictions[k][:].tolist()])
               elif segments_filewise_test[i][1] == 'ST':
                   ST_probabilities.append([spec_id[k][0],  predictions[k][:].tolist()])
               elif segments_filewise_test[i][1] == 'Noise':
                   Noise_probabilities.append([spec_id[k][0],  predictions[k][:].tolist()])
               elif segments_filewise_test[i][1] == 'Both':
                   Both_probabilities.append([spec_id[k][0], predictions[k][:].tolist()])
        if click_detected_flag==False:
            Noise_probabilities.append([file, np.zeros((3,)).tolist()])
                
    return LT_probabilities, ST_probabilities, Noise_probabilities, Both_probabilities                            

fs = 16000
test_dir = "D:\Desktop\Documents\Work\Data\Bat\BAT\CNN experiment\TEST2"
annotation_file_test= "D:\\Desktop\\Documents\\Work\\Data\\Bat\\BAT\\CNN experiment\\TEST2\\Test_dataset.data"
test_fold= "BAT SEARCH TESTS\Test_79" #Test folder where to save all the stats

with open(annotation_file_test) as f:
    segments_filewise_test = json.load(f)
file_number=np.shape(segments_filewise_test)[0]

#inizializations
count_start=0
test_featuress =[]
filewise_output=[] #here we store; file, click detected (true/false), #of spectrogram, final label
TD=0
FD=0
TND=0
FND=0
control_spec=0 #this variable count the file where the click detector found a click that are not providing spectrograms for CNN

#search clicks
for i in range(file_number):
    file = segments_filewise_test[i][0]
    control='False'
    click_label, test_featuress, count_end = ClickSearch(test_dir, file, fs, test_featuress, count_start, Train=False)
    gen_spec= count_end-count_start # numb. of generated spectrograms
    
    #update stored information on test file
    filewise_output.append([file, click_label, gen_spec, 'Noise', segments_filewise_test[i][1]]) #note final label inizialized to 'Noise'
    #if I have a click but not a spectrogram I update
    if click_label=='Click' and gen_spec==0:
        control_spec+=1
        
    #updating metrics count    
    if segments_filewise_test[i][1]=='LT' or segments_filewise_test[i][1]=='ST' or segments_filewise_test[i][1]=='Both':
        if click_label == 'Click':
            TD+=1
        else:
            FND+=1
    else:
        if click_label == 'Click':
            FD+=1
        else:
            TND+=1
    count_start=count_end
    
    
data_test= test_featuress
sg_test=np.ndarray(shape=(np.shape(data_test)[0],np.shape(data_test[0][0])[0], np.shape(data_test[0][0])[1]), dtype=float)
spec_id=[]
test_label=[]
print('Number of test spectrograms', np.shape(data_test)[0])
for i in range(np.shape(data_test)[0]):
    maxg = np.max(data_test[i][0][:])
    sg_test[i][:] = data_test[i][0][:]/maxg
    spec_id.append(data_test[i][1:3])
#    test_label.append(data_test[i][-1])
    
#check:
print('check on spec_id', np.shape(spec_id))    

# Using different train and test datasets
x_test = sg_test
#y_test = target_test

test_images = x_test.reshape(x_test.shape[0],6, 512, 1)
input_shape = (6, 512, 1)

test_images = test_images.astype('float32')
modelpath= "D:\\Desktop\\Documents\\Work\\Data\\Bat\\BAT\\CNN experiment\\TEST2\\BAT SEARCH TESTS\\Test_79\\model_3.h5"    
#recover model
model=load_model(modelpath)
#recovering labels
predictions =model.predict(test_images)
#predictions is an array #imagesX #of classes which entries are the probabilities
#for each classes
#print('test label')
#print(test_label)
LT_prob, ST_prob, Noise_prob, Both_prob =label_probability2(predictions, spec_id, test_label, segments_filewise_test, filewise_output, file_number )
#save probability vectors
import json
f= open('D:\\Desktop\\Documents\\Work\\Data\\Bat\\BAT\\CNN experiment\\TEST2\\BAT SEARCH TESTS\\Test_79\\study3\\LT_spec_prob.data', 'w')
#for line in LT_prob:
 #   f.write(str(line))
  #  f.write('\n')
json.dump(LT_prob,f)
f.close()

f= open('D:\\Desktop\\Documents\\Work\\Data\\Bat\\BAT\\CNN experiment\\TEST2\\BAT SEARCH TESTS\\Test_79\\study3\\ST_spec_prob.data', 'w')
#for line in ST_prob:
#    f.write(str(line))
#    f.write('\n')
json.dump(ST_prob,f)
f.close()

f= open('D:\\Desktop\\Documents\\Work\\Data\\Bat\\BAT\\CNN experiment\\TEST2\\BAT SEARCH TESTS\\Test_79\\study3\\Noise_spec_prob.data', 'w')
#for line in Noise_prob:
#    f.write(str(line))
#    f.write('\n')
json.dump(Noise_prob,f)
f.close()

f= open('D:\\Desktop\\Documents\\Work\\Data\\Bat\\BAT\\CNN experiment\\TEST2\\BAT SEARCH TESTS\\Test_79\\study3\\Both_spec_prob.data', 'w')
json.dump(Both_prob,f)
f.close()

#inizialization
#file_prob_LT=[]
#file_prob_ST=[]
#file_prob_B=[]
#file_prob_Noise=[]
#
#for k in range(file_number):
#    file_label=segments_filewise_test[k][1]
#    if segments_filewise_test[k][0]!=filewise_output[k][0]:
#        print('ERROR in file order')
#        print('Dataset file', segments_filewise_test[k][0] )
#        print('output file',filewise_output[k][0])
#    if file_label=='LT':
#        file_prob_LT.append([filewise_output[k][0],file_probabilities[k][:]])
#    elif file_label=='ST':
#        file_prob_ST.append([filewise_output[k][0],file_probabilities[k][:]])
#    elif file_label=='Both':
#        file_prob_B.append([filewise_output[k][0],file_probabilities[k][:]])
#    elif file_label=='Noise':
#        file_prob_Noise.append([filewise_output[k][0],file_probabilities[k][:]])
#        
##saving probabilities files
##with open('D:\\Desktop\\Documents\\Work\\Data\\Bat\\BAT\\CNN experiment\\TEST2\\BAT SEARCH TESTS\\Test_79\\LT_prob.data', 'w') as f:
##    json.dump(file_prob_LT,f)
#f= open('D:\\Desktop\\Documents\\Work\\Data\\Bat\\BAT\\CNN experiment\\TEST2\\BAT SEARCH TESTS\\Test_79\\LT_prob.data', 'w')
#for line in file_prob_LT:
#    f.write(str(line))
#    f.write('\n')
#f.close()
#
#f= open('D:\\Desktop\\Documents\\Work\\Data\\Bat\\BAT\\CNN experiment\\TEST2\\BAT SEARCH TESTS\\Test_79\\ST_prob.data', 'w')
#for line in file_prob_ST:
#    f.write(str(line))
#    f.write('\n')
#f.close()
#
#f= open('D:\\Desktop\\Documents\\Work\\Data\\Bat\\BAT\\CNN experiment\\TEST2\\BAT SEARCH TESTS\\Test_79\\Both_prob.data', 'w')
#for line in file_prob_B:
#    f.write(str(line))
#    f.write('\n')
#f.close()
#
#f= open('D:\\Desktop\\Documents\\Work\\Data\\Bat\\BAT\\CNN experiment\\TEST2\\BAT SEARCH TESTS\\Test_79\\Noise_prob.data', 'w')
#for line in file_prob_Noise:
#    f.write(str(line))
#    f.write('\n')
#f.close()
#    
##with open('D:\\Desktop\\Documents\\Work\\Data\\Bat\\BAT\\CNN experiment\\TEST2\\BAT SEARCH TESTS\\Test_79\\ST_prob.data', 'w') as f:
##    json.dump(file_prob_ST,f)
##    
##with open('D:\\Desktop\\Documents\\Work\\Data\\Bat\\BAT\\CNN experiment\\TEST2\\BAT SEARCH TESTS\\Test_79\\Both_prob.data', 'w') as f:
##    json.dump(file_prob_B,f)
##    
##with open('D:\\Desktop\\Documents\\Work\\Data\\Bat\\BAT\\CNN experiment\\TEST2\\BAT SEARCH TESTS\\Test_79\\Noise_prob.data', 'w') as f:
##    json.dump(file_prob_Noise,f)
        
    
        
        