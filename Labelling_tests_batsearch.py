# -*- coding: utf-8 -*-
"""
Script to recover file probabilities, like the ones generated by filelabel2
in the script BatSearch.py

This script:
    1) Recover the appropriate model
    2) Predict the labels for the testing dataset
    3) Evaluate the file probabilities with filelabel2
    4) Save files, divided in  true class with the probabilities
"""

import json
import numpy as np
import wavio
import SignalProc
import math
import Segment
import pyqtgraph as pg
import pyqtgraph.exporters as pge
import os

#tensorflow libraries
import tensorflow
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.models import load_model

import librosa
import WaveletSegment
import WaveletFunctions

def ClickSearch(dirName, file, fs, featuress, count, Train=False):
    """
    ClickSearch search for clicks into file in directory dirName, saves 
    dataset, and return click_label and dataset
    
    The search is made on the spectrogram image generated with parameters
    (1024,512)
    Click presence is assested for each spectrogram column: if the mean in the
    frequency band [3000, 5000] (*) is bigger than a treshold we have a click
    thr=mean(all_spec)+std(all_spec) (*)
    
    The clicks are discarded if longer than 0.5 sec
    
    Clicks are stored into featuress using updateDataset
    
    """
    
    print("Click search on ",file)
    filename = dirName + '\\' + file
    
    #Read audiodata
    audiodata = wavio.read(filename)
    sp = SignalProc.SignalProc(1024, 512) #outside?
    sp.data = audiodata.data
    duration=audiodata.nframes/fs
    
    #copyed from sp.wavRead to make everything consistent
    # take only left channel
    if np.shape(np.shape(sp.data))[0] > 1:
        sp.data = sp.data[:, 0]
    sp.audioFormat.setChannelCount(1)
     # force float type
    if sp.data.dtype != 'float':
        sp.data = sp.data.astype('float')
    sp.audioFormat.setSampleSize(audiodata.sampwidth * 8)
    
    #Spectrogram
    sp.samplerate= fs
    sgraw= sp.spectrogram(1024, 512, 'Blackman')
    imspec=(10.*np.log10(sgraw)).T #transpose
    imspec=np.flipud(imspec) #updown 

    df=16000/(np.shape(imspec)[0]+1) #frequency increment 
    dt=duration/(np.shape(imspec)[1]+1) #timeincrement
    up_len=math.ceil(0.5/dt) #0.5 second lenth in indices  
    
    #Frequency band
    f0=3000
    index_f0=-1+math.floor(f0/df) #lower bound needs to be rounded down
#    print(f0,index_f0)
    f1=5000
    index_f1=-1+math.ceil(f1/df) #upper bound needs to be rounded up
    
    #Mean in the frequency band
    mean_spec=np.mean(imspec[index_f0:index_f1,:], axis=0) #added 0.01 to avoid divition by 0

    #Threshold
    mean_spec_all=np.mean(imspec, axis=0)[2:]
    thr_spec=(np.mean(mean_spec_all)+np.std(mean_spec_all))*np.ones((np.shape(mean_spec)))
    
    ##clickfinder
    #check when the mean is bigger than the threshold
    #clicks is an array which elements are equal to 1 only where the sum is bigger 
    #than the mean, otherwise are equal to 0
    clicks=np.where(mean_spec>thr_spec,1,0)
    clicks_indices=np.nonzero(clicks)
    print(np.shape(clicks_indices))
    #check: if I have found somenthing
    if np.shape(clicks_indices)[1]==0:
        #If not: label = None 
        click_label='None'
        #check if I need to return something different
        return click_label, featuress, count
        #not saving spectrograms
    
#    DIscarding segments too long or too shorts and saving spectrogram images
    
    #Read annotation file: if in Train mode
    if Train==True:
        annotation_file=filename +'.data'
        if os.path.isfile(annotation_file):
            segments = Segment.SegmentList()
            segments.parseJSON(annotation_file)
            thisSpSegs = np.arange(len(segments)).tolist()
        else:
            segments=[]
            thisSpSegs=[]
    else:
        segments=[]
        thisSpSegs=[]
        
    click_start=clicks_indices[0][0]
    click_end=clicks_indices[0][0]  
    for i in range(1,np.shape(clicks_indices)[1]):
        if clicks_indices[0][i]==click_end+1:
            click_end=clicks_indices[0][i]
        else:
            if click_end-click_start+1>up_len:
                clicks[click_start:click_end+1]=0
            else:
                #savedataset
                featuress, count=updateDataset3(file, dirName, featuress, count, imspec,  segments, thisSpSegs, click_start, click_end, dt, Train)
                #update
                click_start=clicks_indices[0][i]
                click_end=clicks_indices[0][i] 
                              
    #checking last loop with end
    if click_end-click_start+1>up_len:
        clicks[click_start:click_end+1]=0
    else:
        featuress, count = updateDataset3(file, dirName, featuress, count, imspec, segments, thisSpSegs, click_start, click_end, dt, Train)
        
    #updating click_inidice
    clicks_indices=np.nonzero(clicks)
    
    #Assigning: click label
    if np.shape(clicks_indices)[1]==0:
        click_label='None'
    else:
        click_label='Click'
    
    return click_label, featuress, count

def updateDataset3(file_name, dirName, featuress, count, spectrogram, segments, thisSpSegs, click_start, click_end, dt, Train=False):
    """
    Update Dataset with current segment
    It take a piece of the spectrogram with fixed length centered in the
    click 
    
    TRAIN MODE => stores the lables as well
    A spectrogram is labeled is the click is inside a segment
    We have 3 labels:
        0 => LT
        1 => ST
        2 => Noise
    """
    #I assign a label t the spectrogram only for Train Dataset
    click_start_sec=click_start*dt
    click_end_sec=click_end*dt
    if Train==True:
        assigned_flag=False #control flag
        for segix in thisSpSegs:
            seg = segments[segix]
            if isinstance(seg[4][0], dict):
                if seg[0]<=click_start_sec and seg[1]>=click_end_sec:
                    if 'Bat (Long Tailed)' == seg[4][0]["species"]:
                        spec_label = 0
                        assigned_flag=True
                        break
                    elif 'Bat (Short Tailed)' == seg[4][0]["species"]:
                        spec_label = 1
                        assigned_flag=True
                        break
                    elif 'Noise' == seg[4][0]["species"]:
                        spec_label = 2    
                        assigned_flag=True
                        break
                    else:
                        continue
                    
            elif isinstance(seg[4][0], str):
                # old format
                if seg[0]<=click_start_sec and seg[1]>=click_end_sec:
                    if 'Bat (Long Tailed)' == seg[4][0]["species"]:
                        spec_label = 0
                        assigned_flag=True
                        break
                    elif 'Bat (Short Tailed)' == seg[4][0]["species"]:
                        spec_label = 1
                        assigned_flag=True
                        break
                    elif 'Noise' == seg[4][0]["species"]:
                        spec_label = 2   
                        assigned_flag=True
                        break
                    else:
                        continue
        if assigned_flag==False:
            spec_label=2
    
# slice spectrogram   

    win_pixel=1 
    ls = np.shape(spectrogram)[1]-1
    click_center=int((click_start+click_end)/2)

    start_pixel=click_center-win_pixel
    if start_pixel<0:
        win_pixel2=win_pixel+np.abs(start_pixel)
        start_pixel=0
    else:
        win_pixel2=win_pixel
    
    end_pixel=click_center+win_pixel2
    if end_pixel>ls:
        start_pixel-=end_pixel-ls+1
        end_pixel=ls-1
#    if end_pixel-start_pixel != 10:
#        print("*******************************************",end_pixel,start_pixel)
        #this code above fails for sg less than 4 pixels wide   
    sgRaw=spectrogram[:,start_pixel:end_pixel+1] #not I am saving the spectrogram in the right dimension
    sgRaw=np.repeat(sgRaw,2,axis=1)
    sgRaw=(np.flipud(sgRaw)).T #flipped spectrogram to make it consistent with Niro Mewthod
    if Train==True:
        featuress.append([sgRaw.tolist(), file_name, count, spec_label])
    else:
        featuress.append([sgRaw.tolist(), file_name, count]) #not storing segment and label informations

    count += 1

    return featuress, count

#2nd option: 3 labels, evaluate it filewise
def File_label2(predictions, spec_id, segments_filewise_test, filewise_output, file_number ):
    """
    FIle_label2 use the predictions made by the CNN to update the filewise annotations
    when we have 3 labels: 0 (LT), 1(ST), 2 (Noise)
    
    METHOD: evaluation of probability over files
        P(2)>50% => Noise
        P(0)>70 => LT
        P(1)>70 => ST
        else => Both
    
     TODO: how can I had possible?
    """
   
    
    if len(predictions)!=np.shape(spec_id)[0]:
        print('ERROR: Number of labels is not equal to number of spectrograms' )
    
    file_probabilities=np.zeros((file_number,3))
    # Assesting file label
    for i in range(file_number):
        file = segments_filewise_test[i][0]
        file_prob=np.zeros((1,3))
        spec_num=0   #counts number of spectrograms per file
        #flag: if no click detected no spectrograms
        click_detected_flag=False
        #        looking for all the spectrogram related to this file

        for k in range(np.shape(spec_id)[0]):
            if spec_id[k][0]==file:
                click_detected_flag=True
                spec_num+=1
                file_prob[0][:]+=predictions[k][:]
#                print('check file_prob',file_prob)
        if click_detected_flag==True:
            file_prob/=spec_num
            file_prob*=100
            if file_prob[0][2]>90:
            #if file_prob[0][0]<5 and file_prob[0][1]<5:
                label='Noise'
            elif file_prob[0][0]-file_prob[0][1]>10:
                label='LT'
            elif file_prob[0][1]-file_prob[0][0]>10:
                label='ST'
#            elif file_prob[0][0]>80:
#                label='LT'
#            elif file_prob[0][1]>80:
#                label='ST'
            else:
                label='Both'
            
        else:
#            if no clicks => automatically Noise
            label='Noise'
            
        print('check file_prob',file_prob)
        filewise_output[i][3] = label
#        file_probabilities.append(file_prob)
        file_probabilities[i][:]=file_prob[0][:]
        
    return filewise_output, file_probabilities

def Label_test1(predictions, spec_id, segments_filewise_test, filewise_output, file_number ):
    """
    Label_test1 use the predictions made by the CNN to update the filewise annotations
    when we have 3 labels: 0 (LT), 1(ST), 2 (Noise)
    
    METHOD: evaluation of probability over files
        maxP(0)>50 and maxP(1)>50 => Both
        maxP(0)>50 => LT
        maxP(1)>50 => ST
        else Noise
    
     TODO: how can I had possible?
    """
   
    
    if len(predictions)!=np.shape(spec_id)[0]:
        print('ERROR: Number of labels is not equal to number of spectrograms' )
    
    # Assesting file label
    for i in range(file_number):
        file_probabilities=[]
        file = segments_filewise_test[i][0]
        spec_num=0   #counts number of spectrograms per file
        #flag: if no click detected no spectrograms
        click_detected_flag=False
        #        looking for all the spectrogram related to this file

        for k in range(np.shape(spec_id)[0]):
            if spec_id[k][0]==file:
                click_detected_flag=True
#                spec_num+=1
#                print('check predictions shape', np.shape(predictions[k][:]))
                file_probabilities.append(predictions[k][:])
#                print('check file_prob',file_prob)
        if click_detected_flag==True:
#            print('check file_probabilities', np.shape(file_probabilities))
            file_probabilities=np.asarray(file_probabilities)
            file_probabilities_max=np.amax(file_probabilities, axis=0)
            print('check file_probabilities_max', np.shape(file_probabilities_max))
            LT_prob=file_probabilities_max[0]*100
            ST_prob=file_probabilities_max[1]*100
#            LT_prob=np.amax(file_probabilities[:][0],axis=)*100
#            ST_prob=np.amax(file_probabilities[:][1])*100
#            Noise_prob=np.max(file_probabilities[:][2])*100
            if LT_prob>90:
                label='LT'
            elif ST_prob>90:
                label='ST'
            elif LT_prob>50 and ST_prob>50:
                label='Both'
            else:
                label='Noise'
            
        else:
#            if no clicks => automatically Noise
            label='Noise'

        filewise_output[i][3] = label

    return filewise_output


def label_probability(predictions, spec_id, target_label, segments_filewise_test, filewise_output, file_number ):
    """
    Label_probability
    It evaluates and stores the probabilities vector for each spectrogram
    
    METHOD: evaluation of probability over files
        P(2)>50% => Noise
        P(0)>70 => LT
        P(1)>70 => ST
        else => Both
    
     TODO: how can I had possible?
    """
   
    print('assing spectrograms probabilities') 
    if len(predictions)!=np.shape(spec_id)[0]:
        print('ERROR: Number of labels is not equal to number of spectrograms' )
    
#    file_probabilities=np.zeros((file_number,3))
    LT_probabilities=[]
    ST_probabilities=[]
    Noise_probabilities=[]
    # Assesting file label
    for i in range(file_number):
        file = segments_filewise_test[i][0]
#        file_prob=np.zeros((1,3))
        spec_num=0   #counts number of spectrograms per file
        #flag: if no click detected no spectrograms
        click_detected_flag=False
        #        looking for all the spectrogram related to this file

        for k in range(np.shape(spec_id)[0]):
            if spec_id[k][0]==file:
               click_detected_flag=True
#                spec_num+=1
#                file_prob[0][:]+=predictions[k][:]
#                print('check file_prob',file_prob)
               if target_label[k] == 0:
                   LT_probabilities.append([spec_id[k][0], segments_filewise_test[i][1], predictions[k][:]])
               elif target_label[k] == 1:
                   ST_probabilities.append([spec_id[k][0], segments_filewise_test[i][1],predictions[k][:]])
               elif target_label[k] == 2:
                   Noise_probabilities.append([spec_id[k][0], segments_filewise_test[i][1], predictions[k][:]])
        if click_detected_flag==False:
            Noise_probabilities.append([0, segments_filewise_test[i][1], np.zeros((1,3))])
                
    return LT_probabilities, ST_probabilities, Noise_probabilities
                    
                    
#        if click_detected_flag==True:
#            file_prob/=spec_num
#            file_prob*=100
#            if file_prob[0][2]>90:
#            #if file_prob[0][0]<5 and file_prob[0][1]<5:
#                label='Noise'
#            elif file_prob[0][0]-file_prob[0][1]>10:
#                label='LT'
#            elif file_prob[0][1]-file_prob[0][0]>10:
#                label='ST'
##            elif file_prob[0][0]>80:
##                label='LT'
##            elif file_prob[0][1]>80:
##                label='ST'
#            else:
#                label='Both'
#            
#        else:
##            if no clicks => automatically Noise
#            label='Noise'
#            
#        print('check file_prob',file_prob)
#        filewise_output[i][3] = label
##        file_probabilities.append(file_prob)
#        file_probabilities[i][:]=file_prob[0][:]
        


fs = 16000
test_dir = "D:\Desktop\Documents\Work\Data\Bat\BAT\CNN experiment\TEST2"
annotation_file_test= "D:\\Desktop\\Documents\\Work\\Data\\Bat\\BAT\\CNN experiment\\TEST2\\Test_dataset.data"
test_fold= "BAT SEARCH TESTS\Test_79" #Test folder where to save all the stats
lab_test_fold="Test_79_04"
os.mkdir(test_dir+ '/' + test_fold+'/'+lab_test_fold)

with open(annotation_file_test) as f:
    segments_filewise_test = json.load(f)
file_number=np.shape(segments_filewise_test)[0]

#inizializations
count_start=0
test_featuress =[]
filewise_output=[] #here we store; file, click detected (true/false), #of spectrogram, final label
TD=0
FD=0
TND=0
FND=0
control_spec=0 #this variable count the file where the click detector found a click that are not providing spectrograms for CNN

#search clicks
for i in range(file_number):
    file = segments_filewise_test[i][0]
    control='False'
    click_label, test_featuress, count_end = ClickSearch(test_dir, file, fs, test_featuress, count_start, Train=False)
    gen_spec= count_end-count_start # numb. of generated spectrograms
    
    #update stored information on test file
    filewise_output.append([file, click_label, gen_spec, 'Noise', segments_filewise_test[i][1]]) #note final label inizialized to 'Noise'
    #if I have a click but not a spectrogram I update
    if click_label=='Click' and gen_spec==0:
        control_spec+=1
        
    #updating metrics count    
    if segments_filewise_test[i][1]=='LT' or segments_filewise_test[i][1]=='ST' or segments_filewise_test[i][1]=='Both':
        if click_label == 'Click':
            TD+=1
        else:
            FND+=1
    else:
        if click_label == 'Click':
            FD+=1
        else:
            TND+=1
    count_start=count_end
    
    
data_test= test_featuress
sg_test=np.ndarray(shape=(np.shape(data_test)[0],np.shape(data_test[0][0])[0], np.shape(data_test[0][0])[1]), dtype=float)
spec_id=[]
test_label=[]
print('Number of test spectrograms', np.shape(data_test)[0])
for i in range(np.shape(data_test)[0]):
    maxg = np.max(data_test[i][0][:])
    sg_test[i][:] = data_test[i][0][:]/maxg
    spec_id.append(data_test[i][1:3])
#    test_label.append(data_test[i][-1])
    
#check:
print('check on spec_id', np.shape(spec_id))    

# Using different train and test datasets
x_test = sg_test
#y_test = target_test

test_images = x_test.reshape(x_test.shape[0],6, 512, 1)
input_shape = (6, 512, 1)

test_images = test_images.astype('float32')
modelpath= "D:\\Desktop\\Documents\\Work\\Data\\Bat\\BAT\\CNN experiment\\TEST2\\BAT SEARCH TESTS\\Test_79\\model_3.h5"    
#recover model
model=load_model(modelpath)
#recovering labels
predictions =model.predict(test_images)
#predictions is an array #imagesX #of classes which entries are the probabilities

filewise_output = Label_test1(predictions, spec_id, segments_filewise_test, filewise_output, file_number )

#compare predicted_annotations with segments_filewise_test
#evaluate metrics
    
# inizializing
TD=0
FD=0
FND=0
TND=0
CoCl=0 #correctly classified
NCoCl=0
comparison_annotations = []
confusion_matrix=np.zeros((4,4))
#confusion_matrix[0][:]=['', 'LT', 'ST', 'Both', 'Noise']
#confusion_matrix[:][0]=['', 'LT', 'ST', 'Both', 'Noise']
print('Estimating metrics')
for i in range(file_number):
    assigned_label= filewise_output[i][3]
    correct_label=segments_filewise_test[i][1]
    if correct_label==assigned_label:
        CoCl+=1
        if correct_label=='Noise':
            TND+=1
            confusion_matrix[3][3]+=1
        else:
            TD+=1
            if correct_label=='LT':
                confusion_matrix[0][0]+=1
            elif correct_label=='ST':
                confusion_matrix[1][1]+=1
            elif correct_label=='Both':
                confusion_matrix[2][2]+=1
    else:
        NCoCl+=1
        if correct_label=='Noise':
            FD+=1
            if assigned_label=='LT':
                confusion_matrix[0][3]+=1
            elif assigned_label=='ST':
                confusion_matrix[1][3]+=1
            elif assigned_label=='Both':
                confusion_matrix[2][3]+=1
        elif assigned_label=='Noise':
            FND+=1
            if correct_label=='LT':
                confusion_matrix[3][0]+=1
            elif correct_label=='ST':
                confusion_matrix[3][1]+=1
            elif correct_label=='Both':
                confusion_matrix[3][2]+=1
        else:
            TD+=1
            if correct_label=='LT':
                if assigned_label=='ST':
                    confusion_matrix[1][0]+=1
                elif assigned_label=='Both':
                    confusion_matrix[2][0]+=1
            elif correct_label=='ST':
                if assigned_label=='LT':
                    confusion_matrix[0][1]+=1
                elif assigned_label=='Both':
                    confusion_matrix[2][1]+=1
            elif correct_label=='Both':
                if assigned_label=='LT':
                    confusion_matrix[0][2]+=1
                elif assigned_label=='ST':
                    confusion_matrix[1][2]+=1
            
    comparison_annotations.append([filewise_output[i][0], segments_filewise_test[i][1], assigned_label])
 
#chck
print('number of files =', file_number)
print('TD =',TD)
print('FD =',FD)
print('TND =',TND)
print('FND =',FND)
print('Correct classifications =', CoCl)
print('uncorrect classifications =', NCoCl)
#printng metrics
print("-------------------------------------------")
print("Click Detector stats on Testing Data")
if TD==0:
    Recall=0
else:
    Recall= TD/(TD+FND)*100
print('Recall ', Recall)
if TD==0:
    Precision= 0
else:
    Precision= TD/(TD+FD)*100
print('Precision ', Precision)
if CoCl==0:
    Accuracy=0
else:
    Accuracy = CoCl/(CoCl+NCoCl)*100
print('Accuracy', Accuracy)
TD_rate= (TD/file_number)*100
print('True Detected rate', TD_rate)
FD_rate= (FD/file_number)*100
print('False Detected rate', FD_rate)
FND_rate= (FND/file_number)*100
print('False Negative Detected rate', FND_rate)
TND_rate= (TND/file_number)*100
print('True Negative Detected rate', TND_rate)
CoCl_rate= (CoCl/file_number)*100
print('Correctly Classified rate', CoCl_rate)
NCoCl_rate= (NCoCl/file_number)*100
print('Uncorrectly Classified rate', NCoCl_rate)
print(confusion_matrix)
print("-------------------------------------------")

#saving Click Detector Stats
cd_metrics_file=test_dir+'\\'+test_fold+'\\'+lab_test_fold+'\\bat_detector_stats.txt'
file1=open(cd_metrics_file,"w")
L1=["Bat Detector stats on Testing Data \n"]
L2=['Number of files = %5d \n' %file_number]
L3=['TD = %5d \n' %TD]
L4=['FD = %5d \n' %FD]
L5=['TND = %5d \n' %TND]
L6=['FND = %5d \n' %FND]
L7=['Correctly classified files= %5d \n' %CoCl]
L8=['Uncorrectly classified files= %5d \n' %NCoCl]
L9=["Recall = %3.7f \n" %Recall,"Precision = %3.7f \n" %Precision, "Accuracy = %3.7f \n" %Accuracy, "True Detected rate = %3.7f \n" %TD_rate, "False Detected rate = %3.7f \n" %FD_rate, "True Negative Detected rate = %3.7f \n" %TND_rate, "False Negative Detected rate = %3.7f \n" %FND_rate, "Correctly Classified rate =%3.7f \n" %CoCl_rate, "Uncorrectly Classified rate =%3.7f \n" %NCoCl_rate ]

file1.writelines(np.concatenate((L1,L2,L3,L4, L5, L6, L7, L8, L9)))
file1.close()
       
#saving compared labels
with open(test_dir+'\\' +test_fold+'\\'+lab_test_fold+'\\Test_annotations_comparison.data', 'w') as f:
    json.dump(comparison_annotations,f)


#saving compared labels
with open(test_dir+'\\' +test_fold+'\\Test_filewise_output.data', 'w') as f:
    json.dump(filewise_output,f)
    
        
        